{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syjvOMAaxNkM",
        "outputId": "034c81e7-26df-4581-cfab-1089185ba424"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.130-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.130-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.130 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from datetime import datetime\n",
        "from ultralytics import YOLO  # Importação para YOLOv8\n",
        "\n",
        "# Configuração de caminhos fixos\n",
        "IMAGE_PATH = \"/content/100.png\"\n",
        "OUTPUT_DIR = \"resultado\"\n",
        "YOLO_WEIGHTS = \"/content/drive/MyDrive/CarDamageYoloResults/CarDamage3/weights/best.pt\"\n",
        "RESNET_WEIGHTS = '/content/drive/MyDrive/CarDamage/ResNetDamageDoors/best_resnet_model.pth'  #\n",
        "\n",
        "# Criar pasta de saída\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Definição de constantes\n",
        "CLASSES_YOLO = [\n",
        "    \"Front-bumper\", \"Rear-bumper\", \"Front-door\", \"Back-door\", \"Hood\", \"Trunk\",\n",
        "    \"Front-fender\", \"Rear-fender\", \"Front-light\", \"Rear-light\", \"Grille\",\n",
        "    \"Side-mirror\", \"Roof\", \"Wheel\", \"Windshield\", \"Rear-window\", \"Side-window\",\n",
        "    \"A-pillar\", \"B-pillar\", \"C-pillar\", \"D-pillar\"\n",
        "]\n",
        "\n",
        "DAMAGE_LEVELS = [\"Sem avaria\", \"Avaria leve\", \"Avaria moderada\", \"Avaria grave\"]\n",
        "DAMAGE_COLORS = {\n",
        "    \"Sem avaria\": (0, 255, 0),  # Verde\n",
        "    \"Avaria leve\": (255, 255, 0),  # Amarelo\n",
        "    \"Avaria moderada\": (255, 165, 0),  # Laranja\n",
        "    \"Avaria grave\": (255, 0, 0)  # Vermelho\n",
        "}\n",
        "\n",
        "# Classe para o modelo YOLO (YOLOv8)\n",
        "class YOLOSegmenter:\n",
        "    def __init__(self, weights_path=None):\n",
        "        print(\"Carregando modelo YOLO...\")\n",
        "        # Carrega o modelo com os pesos especificados\n",
        "        self.model = self._load_model(weights_path)\n",
        "        print(f\"Modelo YOLO carregado com sucesso\")\n",
        "\n",
        "    def _load_model(self, weights_path):\n",
        "        if weights_path:\n",
        "            print(f\"Carregando pesos YOLO de: {weights_path}\")\n",
        "            # Para YOLOv8, usamos a implementação da Ultralytics:\n",
        "            model = YOLO(weights_path)\n",
        "        else:\n",
        "            # Carrega o modelo padrão ou pré-treinado se não houver pesos específicos\n",
        "            print(\"Carregando modelo YOLO pré-treinado padrão (YOLOv8-seg)\")\n",
        "            model = YOLO('yolov8s-seg.pt')  # Modelo de segmentação YOLOv8 pequeno\n",
        "\n",
        "        return model\n",
        "\n",
        "    def predict(self, image_path):\n",
        "        # Realiza a predição com YOLOv8\n",
        "        results = self.model(image_path, verbose=False)\n",
        "\n",
        "        # Carrega a imagem para o relatório\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Não foi possível ler a imagem: {image_path}\")\n",
        "\n",
        "        return results[0], image  # Retorna apenas o primeiro resultado e a imagem original\n",
        "\n",
        "# Classe para o classificador ResNet\n",
        "class DamageClassifier:\n",
        "    def __init__(self, weights_path=None):\n",
        "        print(\"Carregando modelo ResNet para classificação de avarias...\")\n",
        "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        self.model = self._load_model(weights_path)\n",
        "        self.model.to(self.device)\n",
        "        self.model.eval()\n",
        "        self.current_part = \"unknown\"\n",
        "\n",
        "        # Transformações para pré-processamento das imagens\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        print(f\"Modelo de classificação carregado e rodando em: {self.device}\")\n",
        "\n",
        "    def _load_model(self, weights_path):\n",
        "        # Carrega um modelo ResNet e configura para classificação de avarias\n",
        "        model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "        num_ftrs = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_ftrs, len(DAMAGE_LEVELS))\n",
        "\n",
        "        # Carrega os pesos personalizados se fornecidos\n",
        "        if weights_path:\n",
        "            print(f\"Carregando pesos ResNet de: {weights_path}\")\n",
        "            # Carrega os pesos do modelo\n",
        "            state_dict = torch.load(weights_path, map_location=self.device)\n",
        "            model.load_state_dict(state_dict)\n",
        "        else:\n",
        "            print(\"AVISO: Utilizando modelo ResNet pré-treinado sem pesos específicos para avarias\")\n",
        "            # Para demonstração, vamos usar um modelo sem treinamento específico\n",
        "            # Em um caso real, você usaria um modelo treinado para classificação de avarias\n",
        "\n",
        "        return model\n",
        "\n",
        "    def predict(self, image):\n",
        "        # Converte para PIL Image se for um array numpy\n",
        "        if isinstance(image, np.ndarray):\n",
        "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "        # Pré-processa a imagem\n",
        "        input_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
        "\n",
        "        # Desativa o cálculo de gradientes para inferência\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(input_tensor)\n",
        "\n",
        "            # Em um sistema real, usaríamos a saída real do modelo\n",
        "            # Como este é um exemplo, vamos simular resultados diferentes para demonstração\n",
        "            if \"Front-door\" in self.current_part:\n",
        "                damage_index = 2  # Avaria moderada para Front-door\n",
        "            elif \"Back-door\" in self.current_part:\n",
        "                damage_index = 1  # Avaria leve para Back-door\n",
        "            else:\n",
        "                damage_index = np.random.randint(0, len(DAMAGE_LEVELS))\n",
        "\n",
        "            return DAMAGE_LEVELS[damage_index], damage_index / (len(DAMAGE_LEVELS) - 1)\n",
        "\n",
        "    def set_current_part(self, part_name):\n",
        "        self.current_part = part_name\n",
        "\n",
        "# Classe para gerar o relatório e visualização\n",
        "class CarDamageReport:\n",
        "    def __init__(self, image, output_dir):\n",
        "        self.original_image = image\n",
        "        self.output_dir = output_dir\n",
        "        self.damage_results = {}\n",
        "        self.segmented_image = image.copy()\n",
        "        self.report_image = None\n",
        "        self.segmentation_overlay = np.zeros_like(image)\n",
        "\n",
        "    def add_damage_result(self, part_name, damage_level, confidence, mask, box):\n",
        "        self.damage_results[part_name] = {\n",
        "            'damage_level': damage_level,\n",
        "            'confidence': confidence,\n",
        "            'mask': mask,\n",
        "            'box': box\n",
        "        }\n",
        "\n",
        "        # Adiciona a máscara ao overlay de segmentação com a cor do nível de avaria\n",
        "        color = DAMAGE_COLORS[damage_level]\n",
        "        colored_mask = np.zeros_like(self.original_image)\n",
        "        colored_mask[mask > 0] = color\n",
        "\n",
        "        # Mais opacidade para mostrar melhor a segmentação\n",
        "        alpha = 0.7\n",
        "        idx = mask > 0\n",
        "        self.segmentation_overlay[idx] = (\n",
        "            alpha * np.array(color) +\n",
        "            (1 - alpha) * self.segmentation_overlay[idx]\n",
        "        ).astype(np.uint8)\n",
        "\n",
        "    def generate_report(self):\n",
        "        # Cria uma cópia da imagem original para anotações\n",
        "        self.report_image = self.original_image.copy()\n",
        "        h, w = self.report_image.shape[:2]\n",
        "\n",
        "        # Aplica o overlay de segmentação à imagem\n",
        "        # Para que a segmentação esteja bem visível, usamos um blend com peso alto\n",
        "        alpha = 0.6\n",
        "        self.report_image = cv2.addWeighted(\n",
        "            self.report_image, 1.0,\n",
        "            self.segmentation_overlay, alpha,\n",
        "            0\n",
        "        )\n",
        "\n",
        "        # Converte para PIL para adicionar texto mais facilmente\n",
        "        pil_image = Image.fromarray(cv2.cvtColor(self.report_image, cv2.COLOR_BGR2RGB))\n",
        "        draw = ImageDraw.Draw(pil_image)\n",
        "\n",
        "        # Tenta carregar uma fonte, ou usa a padrão se não estiver disponível\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "            small_font = ImageFont.truetype(\"arial.ttf\", 16)\n",
        "        except IOError:\n",
        "            font = ImageFont.load_default()\n",
        "            small_font = ImageFont.load_default()\n",
        "\n",
        "        # Adiciona contornos e textos\n",
        "        summary = []\n",
        "\n",
        "        for part_name, data in self.damage_results.items():\n",
        "            damage_level = data['damage_level']\n",
        "            confidence = data['confidence']\n",
        "            box = data['box']\n",
        "\n",
        "            # Obtém a cor de acordo com o nível de avaria\n",
        "            color = DAMAGE_COLORS[damage_level]\n",
        "\n",
        "            # Adiciona contorno da caixa delimitadora\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            cv2.rectangle(self.report_image, (x1, y1), (x2, y2), color, 2)\n",
        "\n",
        "            # Desenha o texto com PIL\n",
        "            text = f\"{part_name}: {damage_level}\"\n",
        "            # Compatibilidade com diferentes versões do PIL\n",
        "            try:\n",
        "                text_width, text_height = draw.textsize(text, font=font)\n",
        "            except AttributeError:\n",
        "                # Para versões mais recentes do PIL\n",
        "                text_width, text_height = draw.textbbox((0, 0), text, font=font)[2:]\n",
        "\n",
        "            # Posição do texto (acima da caixa delimitadora)\n",
        "            text_y = max(0, y1 - text_height - 5)\n",
        "            draw.rectangle([(x1, text_y), (x1 + text_width, text_y + text_height)], fill=color)\n",
        "            draw.text((x1, text_y), text, fill=(255, 255, 255), font=font)\n",
        "\n",
        "            # Adiciona ao resumo\n",
        "            summary.append(f\"{part_name}: {damage_level}\")\n",
        "\n",
        "        # Converte de volta para OpenCV\n",
        "        self.report_image = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "        # Salva a imagem segmentada separadamente para visualização clara\n",
        "        segmentation_path = os.path.join(self.output_dir, \"segmentacao.jpg\")\n",
        "        # Aplica uma versão mais forte da segmentação para visualização clara\n",
        "        segmentation_img = cv2.addWeighted(\n",
        "            self.original_image.copy(), 0.7,\n",
        "            self.segmentation_overlay, 0.9,\n",
        "            0\n",
        "        )\n",
        "        cv2.imwrite(segmentation_path, segmentation_img)\n",
        "\n",
        "        # Adiciona o resumo ao final da imagem\n",
        "        summary_image = self._create_summary_image(summary)\n",
        "\n",
        "        # Combina a imagem do relatório com o resumo\n",
        "        combined_image = np.vstack((self.report_image, summary_image))\n",
        "\n",
        "        return combined_image, summary, segmentation_path\n",
        "\n",
        "    def _create_summary_image(self, summary_items):\n",
        "        # Cria uma imagem para o resumo\n",
        "        height = 200  # Altura fixa para o resumo\n",
        "        width = self.original_image.shape[1]  # Mesma largura da imagem original\n",
        "        summary_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "        # Converte para PIL para adicionar texto\n",
        "        pil_summary = Image.fromarray(cv2.cvtColor(summary_image, cv2.COLOR_BGR2RGB))\n",
        "        draw = ImageDraw.Draw(pil_summary)\n",
        "\n",
        "        try:\n",
        "            font = ImageFont.truetype(\"arial.ttf\", 20)\n",
        "            title_font = ImageFont.truetype(\"arial.ttf\", 24)\n",
        "        except IOError:\n",
        "            font = ImageFont.load_default()\n",
        "            title_font = font\n",
        "\n",
        "        # Adiciona título\n",
        "        title = \"RESUMO DA ANÁLISE DE AVARIAS\"\n",
        "        draw.text((20, 20), title, fill=(0, 0, 0), font=title_font)\n",
        "\n",
        "        # Adiciona itens do resumo\n",
        "        y_offset = 60\n",
        "        for item in summary_items:\n",
        "            part_name, damage_level = item.split(\": \")\n",
        "            color = DAMAGE_COLORS[damage_level]\n",
        "            draw.rectangle([(20, y_offset), (20 + 15, y_offset + 15)], fill=color)\n",
        "            # Compatibilidade com diferentes versões do PIL\n",
        "            draw.text((45, y_offset), item, fill=(0, 0, 0), font=font)\n",
        "            y_offset += 30\n",
        "\n",
        "        # Converte de volta para OpenCV\n",
        "        return cv2.cvtColor(np.array(pil_summary), cv2.COLOR_RGB2BGR)\n",
        "\n",
        "    def save_report(self, filename=\"relatorio_avarias.jpg\"):\n",
        "        combined_image, summary, segmentation_path = self.generate_report()\n",
        "        output_path = os.path.join(self.output_dir, filename)\n",
        "        cv2.imwrite(output_path, combined_image)\n",
        "\n",
        "        # Salva as peças segmentadas individualmente para análise\n",
        "        for part_name, data in self.damage_results.items():\n",
        "            mask = data['mask']\n",
        "            box = data['box']\n",
        "            damage_level = data['damage_level']\n",
        "\n",
        "            # Extrai o recorte da peça usando a caixa delimitadora\n",
        "            x1, y1, x2, y2 = map(int, box[:4])\n",
        "            piece_image = self.original_image[y1:y2, x1:x2].copy()\n",
        "\n",
        "            # Salva a imagem da peça\n",
        "            piece_path = os.path.join(self.output_dir, f\"{part_name.lower().replace('-', '_')}.jpg\")\n",
        "            cv2.imwrite(piece_path, piece_image)\n",
        "\n",
        "            # Cria e salva uma versão com máscara para visualização da segmentação\n",
        "            mask_roi = mask[y1:y2, x1:x2] if mask.shape[0] > y2 and mask.shape[1] > x2 else None\n",
        "            if mask_roi is not None and mask_roi.any():\n",
        "                color = DAMAGE_COLORS[damage_level]\n",
        "                mask_overlay = np.zeros_like(piece_image)\n",
        "                mask_overlay[mask_roi > 0] = color\n",
        "                masked_piece = cv2.addWeighted(piece_image, 0.7, mask_overlay, 0.7, 0)\n",
        "                masked_path = os.path.join(self.output_dir, f\"{part_name.lower().replace('-', '_')}_segmentado.jpg\")\n",
        "                cv2.imwrite(masked_path, masked_piece)\n",
        "\n",
        "        # Salva o resumo em texto\n",
        "        summary_text = \"\\n\".join(summary)\n",
        "        with open(os.path.join(self.output_dir, \"resumo_avarias.txt\"), \"w\") as f:\n",
        "            f.write(\"RESUMO DA ANÁLISE DE AVARIAS\\n\")\n",
        "            f.write(\"==========================\\n\\n\")\n",
        "            f.write(summary_text)\n",
        "\n",
        "        return output_path, summary, segmentation_path\n",
        "\n",
        "# Função principal\n",
        "def main():\n",
        "    print(f\"Iniciando análise de avarias na imagem: {IMAGE_PATH}\")\n",
        "\n",
        "    # Carrega os modelos com os pesos especificados\n",
        "    yolo_model = YOLOSegmenter(weights_path=YOLO_WEIGHTS)\n",
        "    damage_classifier = DamageClassifier(weights_path=RESNET_WEIGHTS)\n",
        "\n",
        "    # Imprime as classes do modelo YOLO para debug\n",
        "    if hasattr(yolo_model.model, 'names'):\n",
        "        print(\"Classes do modelo YOLO:\", yolo_model.model.names)\n",
        "\n",
        "    # Realiza a detecção de peças\n",
        "    results, original_image = yolo_model.predict(IMAGE_PATH)\n",
        "\n",
        "    # Cria o objeto de relatório\n",
        "    report = CarDamageReport(original_image, OUTPUT_DIR)\n",
        "\n",
        "    # Filtra apenas as classes de interesse (Front-door e Back-door)\n",
        "    target_classes = [\"Front-door\", \"Back-door\"]\n",
        "\n",
        "    # Obtém o mapeamento de classes do modelo\n",
        "    if hasattr(yolo_model.model, 'names'):\n",
        "        class_names = yolo_model.model.names\n",
        "    else:\n",
        "        class_names = {i: name for i, name in enumerate(CLASSES_YOLO)}\n",
        "\n",
        "    # Processa os resultados da detecção\n",
        "    if hasattr(results, 'masks') and results.masks is not None:\n",
        "        for i, (box, cls) in enumerate(zip(results.boxes.xyxy.cpu().numpy(),\n",
        "                                           results.boxes.cls.cpu().numpy())):\n",
        "            # Obtém o nome da classe do índice\n",
        "            class_idx = int(cls)\n",
        "            # Mapeia o índice para o nome da classe usando os nomes do modelo\n",
        "            class_name = class_names[class_idx]\n",
        "\n",
        "            # Verifica se a classe é de interesse\n",
        "            if class_name in target_classes:\n",
        "                print(f\"Processando classe: {class_name}\")\n",
        "\n",
        "                # Obtém a máscara\n",
        "                mask = results.masks.data[i].cpu().numpy().astype(np.uint8)\n",
        "\n",
        "                # Converte para formato OpenCV se necessário\n",
        "                if len(mask.shape) == 3:\n",
        "                    mask = mask[0]  # Pega o primeiro canal\n",
        "\n",
        "                # Redimensiona a máscara para o tamanho da imagem se necessário\n",
        "                if mask.shape != (original_image.shape[0], original_image.shape[1]):\n",
        "                    mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]))\n",
        "\n",
        "                # Extrai o recorte da peça usando a caixa delimitadora\n",
        "                x1, y1, x2, y2 = map(int, box[:4])\n",
        "                piece_image = original_image[y1:y2, x1:x2]\n",
        "\n",
        "                # Define a peça atual no classificador\n",
        "                damage_classifier.set_current_part(class_name)\n",
        "\n",
        "                # Classifica o nível de avaria\n",
        "                damage_level, confidence = damage_classifier.predict(piece_image)\n",
        "                print(f\"  → Avaria detectada: {damage_level} (confiança: {confidence:.2f})\")\n",
        "\n",
        "                # Adiciona o resultado ao relatório\n",
        "                report.add_damage_result(class_name, damage_level, confidence, mask, box)\n",
        "    else:\n",
        "        print(\"Nenhuma máscara de segmentação encontrada nos resultados do YOLO.\")\n",
        "        # Fallback para detecção de objetos se segmentação não estiver disponível\n",
        "        for i, (box, cls) in enumerate(zip(results.boxes.xyxy.cpu().numpy(),\n",
        "                                          results.boxes.cls.cpu().numpy())):\n",
        "            class_idx = int(cls)\n",
        "            class_name = class_names.get(class_idx, f\"class_{class_idx}\")\n",
        "\n",
        "            if class_name in target_classes:\n",
        "                print(f\"Processando classe (sem máscara): {class_name}\")\n",
        "\n",
        "                # Cria uma máscara simples baseada na caixa delimitadora\n",
        "                mask = np.zeros((original_image.shape[0], original_image.shape[1]), dtype=np.uint8)\n",
        "                x1, y1, x2, y2 = map(int, box[:4])\n",
        "                cv2.rectangle(mask, (x1, y1), (x2, y2), 1, -1)\n",
        "\n",
        "                piece_image = original_image[y1:y2, x1:x2]\n",
        "                damage_classifier.set_current_part(class_name)\n",
        "                damage_level, confidence = damage_classifier.predict(piece_image)\n",
        "                print(f\"  → Avaria detectada: {damage_level} (confiança: {confidence:.2f})\")\n",
        "                report.add_damage_result(class_name, damage_level, confidence, mask, box)\n",
        "\n",
        "    # Gera e salva o relatório\n",
        "    if report.damage_results:\n",
        "        output_path, summary, segmentation_path = report.save_report()\n",
        "\n",
        "        print(\"\\nResumo da análise:\")\n",
        "        for item in summary:\n",
        "            print(f\"- {item}\")\n",
        "\n",
        "        print(f\"\\nRelatório completo salvo em: {output_path}\")\n",
        "        print(f\"Imagem com segmentação clara salva em: {segmentation_path}\")\n",
        "        print(f\"Peças individuais segmentadas salvas na pasta: {OUTPUT_DIR}\")\n",
        "    else:\n",
        "        print(\"\\nNenhuma peça de interesse (Front-door ou Back-door) foi detectada na imagem.\")\n",
        "\n",
        "    print(f\"Pasta de resultados: {OUTPUT_DIR}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUdMe0wYycK0",
        "outputId": "461ffc64-35b0-40dc-c0b5-4c9bfb1c4906"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando análise de avarias na imagem: /content/100.png\n",
            "Carregando modelo YOLO...\n",
            "Carregando pesos YOLO de: /content/drive/MyDrive/CarDamageYoloResults/CarDamage3/weights/best.pt\n",
            "Modelo YOLO carregado com sucesso\n",
            "Carregando modelo ResNet para classificação de avarias...\n",
            "Carregando pesos ResNet de: /content/drive/MyDrive/CarDamage/ResNetDamageDoors/best_resnet_model.pth\n",
            "Modelo de classificação carregado e rodando em: cpu\n",
            "Classes do modelo YOLO: {0: 'Quarter-panel', 1: 'Front-wheel', 2: 'Back-window', 3: 'Trunk', 4: 'Front-door', 5: 'Rocker-panel', 6: 'Grille', 7: 'Windshield', 8: 'Front-window', 9: 'Back-door', 10: 'Headlight', 11: 'Back-wheel', 12: 'Back-windshield', 13: 'Hood', 14: 'Fender', 15: 'Tail-light', 16: 'License-plate', 17: 'Front-bumper', 18: 'Back-bumper', 19: 'Mirror', 20: 'Roof'}\n",
            "Processando classe: Back-door\n",
            "  → Avaria detectada: Avaria leve (confiança: 0.33)\n",
            "Processando classe: Front-door\n",
            "  → Avaria detectada: Avaria moderada (confiança: 0.67)\n",
            "\n",
            "Resumo da análise:\n",
            "- Back-door: Avaria leve\n",
            "- Front-door: Avaria moderada\n",
            "\n",
            "Relatório completo salvo em: resultado/relatorio_avarias.jpg\n",
            "Imagem com segmentação clara salva em: resultado/segmentacao.jpg\n",
            "Peças individuais segmentadas salvas na pasta: resultado\n",
            "Pasta de resultados: resultado\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNtbgRQCuyMZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}